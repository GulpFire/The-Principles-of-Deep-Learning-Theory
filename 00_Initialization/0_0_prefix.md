# 第 0 章 初始设定
> 模拟是这样的：人们通常同时感知数十亿个基本过程的总和，因此大数均衡定律完全掩盖了单个过程的真实性质。
>
> —— John von Neumann

由于对计算机技术的大量研究，现代`人工智能(AI)`系统现在可以配备数十亿个基本组件。当这些组件被正确初始化并进行训练时，人工智能可以完成一度被认为极其复杂的任务，哲学家们此前曾认为只有自然智能系统（即人类）才能完成这些任务。

人工智能的成功背后是`深度学习`。深度学习使用人工`神经网络`作为人工智能的基础模型：虽然人工神经网络松散地基于生物神经网络，例如你的大脑，但人工神经网络可能被认为是一种特别好的方法，可以指定一组灵活的功能，由许多称为`神经元`的基本计算块构建而成。这种计算模型实际上与你可能用来阅读本书的计算机的计算模型截然不同。特别是，深度学习模型不是通过编写一组特定的指令来直接解决问题，而是根据来自真实世界的数据进行训练，学习如何解决问题。

深度学习框架的真正力量来自深度神经网络，其中许多神经元并行组织成连续的计算层，学习世界的有用表示。这种表示学习将数据转化为越来越精细的形式，有助于解决潜在任务，并被认为是人工智能和生物智能成功的标志。

尽管取得了这些成功并引起了人们的极大兴趣，深度学习理论仍处于起步阶段。事实上，理论和实践之间存在着严重的脱节：虽然从业者已经达到了惊人的里程碑，远远超过了理论家，但他们的分析往往涉及到不切实际的假设，从而得出了与理解深度神经网络（通常使用的深度神经网络）无关的结论。更重要的是，很少有理论工作直接面对深度学习，尽管大量的经验证据表明深度学习在框架成功中的重要性。

本书的目标是提出一套`原则`，使我们能够从理论上分析具有实际相关性的深层神经网络。为了让你开始这项任务，在本章的其余部分，我们将从很高的层次上解释
1. 为什么这样的目标在理论上甚至可以实现。
2. 我们如何在实践中实现。