# 0.1 一种有效的理论方法
> 蒸汽导航将最遥远的国家拉近了距离。他们的理论很少被理解，而改进他们的尝试仍然几乎是偶然的。我们现在建议对这些问题进行仔细审查
>
> —— Sadi Carnot, commenting on the need for a theory of deep learning

虽然现代深度学习模型是由看似无数的基本计算组件构建而成的，但一个经过训练的神经网络是如何从这些低级组件计算函数的`第一原理`微观描述是完全显而易见的。这种微观描述只是将输入通过多个组件层转换为输出的一组指令。重要的是，在训练过程中，这些组件会进行非常精细的调整，对于系统产生有用的输出，需要了解特定的调节。

不幸的是，这些调节的复杂性掩盖了对为什么深度神经网络计算特定函数而不是另一个函数的宏观理解。在这样的计算中，许多神经元执行不同的任务，我们似乎不该抱有可以用理论来完全理解这些模型的希望，觉得用一套小的数学原理就足以完成这项工作是不现实的。

幸运的是，`理论物理学`有一个悠久的传统，即找到具有大量组件的复杂系统的简单`有效`理论。物理程序在模拟我们的物理宇宙方面取得的巨大成功表明，也许某些相同的工具对理论上理解深度神经网络也有用。为了激发这种联系，让我们简单地回顾一下热力学和统计力学的成功，这些物理理论共同从微观第一原理解释了具有许多基本成分的系统的宏观行为。

作为工业时代的科学成果，`热力学`起源于对蒸汽机的描述和创新，蒸汽机是一个由许多粒子组成的系统，也许是最初的黑匣子。从仔细的经验观察中得出的热力学定律被用来编纂蒸汽力学，为这些正在改变社会的宏观人工机器提供了高层次的理解。热力学的出现极大地提高了蒸汽动力效率，但它的定律绝不是基本原理。

直到很久以后，麦克斯韦、玻尔兹曼和吉布斯才在实验得出的有效描述和第一原理理论之间找到了缺失的联系。他们的`统计力学`解释了描述人类规模机器的宏观热力学定律是如何从许多微观基本成分的确定性动力学中产生的。从这个角度来看，热力学定律是一种新兴现象，它只出现在大量微观粒子的集体统计行为中。事实上，正是从统计力学中得出的详细理论预测最终导致了科学界普遍接受物质实际上是由分子和原子组成的。统计力学的不懈应用导致了量子力学的发现，这是为信息时代提供动力的晶体管发明的先驱，从长远来看，正是它让我们开始实现能够智能思考的人工机器。

值得注意的是，这些物理理论源于理解人造人类工程物体的愿望，例如蒸汽机。尽管存在潜在的误解，物理学并不区分自然现象和人工现象。最根本的是，它关注的是提供一套统一的原则，解释过去的经验观察并预测未来实验的结果；理论计算的重点是将可测量的结果或`可观测`值直接与定义理论的基本基本常数或`参数`联系起来。这一观点还意味着模型的预测精度与其数学可处理性之间的权衡，任何理论要成功，前者必须优先于后者：从理论到物理现实的短距离是必不可少的。一旦0成功，这些理论将带来对现象的全面理解和技术的实际进步，从蒸汽时代到信息时代的统计物理学桥梁就是例证。

对于我们对深度学习的研究，这一讨论的关键是，当一个理论问题由许多基本组件组成时，它会简化。此外，与装在一箱蒸汽中的水分子不同——水分子的存在曾经是一个需要实验验证的有争议的猜想——组成深层神经网络的神经元由我们亲手实现（成黑箱）的。事实上，在这种情况下，我们已经理解了微观规律——网络是如何计算的——因此我们的任务是理解宏观尺度上出现的新型规律——为什么它计算一个特定函数而不是另一个——这些规律来自于这些规模庞大的深度学习模型的统计特性。

