# 预训练
> 我对这门课的记忆最深的是一开始，当他开始上课时，他并没有深入的自然原理，也没有做一些实验，而是回顾了高斯积分。显然，需要做一些计算
>
> —— Joe Polchinski, reminiscing about Richard Feynman’s quantum mechanics class

本书的目标是发展能够从理论上理解深度学习的原理。也许最重要的原理是，宽和深的神经网络由近似高斯分布控制。因此，要读完这本书，你需要掌握高斯积分和微扰理论。本章中的预培训包括对这些工具包的快速介绍，以及我们需要的统计中的一些关键概念的简要概述。唯一的先决条件是精通线性代数、多变量微积分和基本概率理论。

考虑到这一点，我们从 §1.1 开始对高斯积分进行扩展讨论。我们的重点将放在计算高斯分布的单项式平均值的计算工具上，最终得出Wick定理。

接下来，在 §1.2 中，我们首先对期望值和可观测值进行一般性讨论。将可观测作为通过重复实验学习概率分布的一种方式，我们得到了矩和累积的统计概念，以及相应的物理学家的全 $M$ 点相关器和连通 $M$ 点相关的概念。特别强调连接的相关器，因为它们直接表征了分布与高斯性的偏差。

在 §1.3 中，我们介绍了概率分布的负对数概率或作用表示，并解释了作用如何使我们系统地变形高斯分布，以给出非高斯分布的紧凑表示。特别是，我们专门研究了接近高斯分布，对于这种分布，高斯性的偏差是通过动作中的小耦合实现的，并展示了扰动理论如何用于将非高斯耦合连接到可观测值，例如连接的相关器。通过微扰地处理这种耦合，我们可以将近似高斯分布的任何相关器转换为高斯积分的和；然后，每个积分都可以通过我们在 §1.1 中开发的工具进行评估。这将是我们最重要的技巧之一，因为我们将研究的神经网络都由近似高斯分布控制，非高斯耦合随着网络变宽而变得扰动小。

由于所有这些操作都需要掌握在我们手中，因此在第一章中，我们错误地在文字、方程式和示例中过于冗长，目的是使这些材料尽可能透明和易于理解。
